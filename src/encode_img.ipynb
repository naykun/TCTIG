{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy\n",
    "import lmdb\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from dataset import CVLGLocalizedNarrativesDataset\n",
    "cvlg_lmdb = '/s2_md0/v-kunyan/CVLG_data/coco_train.lmdb',\n",
    "config_dict = {\"path\":cvlg_lmdb,\n",
    "    \"max_readers\":1,\n",
    "    \"readonly\":False,\n",
    "    \"lock\":False,\n",
    "    \"readahead\":False,\n",
    "    \"meminit\":False,\n",
    "    \"map_size\":214748364800}\n",
    "env2 = lmdb.open(**config_dict) \n",
    "txnout = env2.begin(write=True)\n",
    "\n",
    "cnt = 0\n",
    "keys = set()\n",
    "from utils import load_yaml\n",
    "config = load_yaml(\"./config/caption_coco2017.yaml\")\n",
    "# print(config.dataset_config.cvlg_coco2017)\n",
    "dataset = CVLGLocalizedNarrativesDataset(config.dataset_config.cvlg_coco2017, dataset_type=\"train\")\n",
    "print(len(dataset))\n",
    "from dalle_pytorch import OpenAIDiscreteVAE\n",
    "from tqdm import tqdm\n",
    "vae = OpenAIDiscreteVAE().cuda()\n",
    "for idx, sample in enumerate(tqdm(dataset, total=len(dataset))):\n",
    "    code = vae.get_codebook_indices(sample[\"image\"].unsqueeze(0).cuda())\n",
    "\n",
    "    anno = json.loads(line.strip())\n",
    "    dataset_id = anno[\"dataset_id\"]\n",
    "    ln_image_id = anno[\"image_id\"]\n",
    "#             print(dataset_id)\n",
    "    key = f\"{dataset_id}_{str(cnt).zfill(8)}_{str(ln_image_id).zfill(12)}\".encode()\n",
    "#             print(key)\n",
    "    assert key not in keys\n",
    "    keys.add(key)\n",
    "#             keys.append(key)\n",
    "    txnout.put(key,pickle.dumps(anno))\n",
    "#             print(anno)\n",
    "    cnt += 1\n",
    "    if cnt % 1000 == 0:\n",
    "        txnout.commit()\n",
    "        env2.close()\n",
    "        env2 = lmdb.open(**config_dict) \n",
    "\n",
    "        txnout = env2.begin(write=True)\n",
    "txnout.put(b\"keys\",pickle.dumps(keys))\n",
    "txnout.commit()\n",
    "env2.close()\n",
    "            # env2 = lmdb.open(\n",
    "            #     '/s1_md0/v-kunyan/kunyan/kvlb/mmf_cache/data/datasets/localized_narratives/defaults/annotations/coco_train_localized_narratives.lmdb',\n",
    "            #     max_readers=1,\n",
    "            #     readonly=False,\n",
    "            #     lock=False,\n",
    "            #     readahead=False,\n",
    "            #     meminit=False,\n",
    "            #     map_size=214748364800,\n",
    "            #     # writemap=True,\n",
    "            #     # map_async=True\n",
    "            # ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('DALLE': conda)",
   "name": "python388jvsc74a57bd00ad187540681a93b03f12642b3922d187121ea0074b034de4a122ad5ecb5fd28"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "0ad187540681a93b03f12642b3922d187121ea0074b034de4a122ad5ecb5fd28"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}