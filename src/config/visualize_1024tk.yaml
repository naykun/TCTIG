includes:
  - ./traced_caption_anno_lmdb_img_itp.yaml
  - ./defaults.yaml

model_config:
    cvlg:
      concate_trace: true
      deepspeed: false
      base_model_name: t2i-2layer
      max_gen_length: 1024
      loop_contrastive: false
      tc_contrastive_aggregate_method: transformer
      inference:
        prompt: false
        type: nucleus_sampling
        args: 
          do_sample: true
          max_length: 1025
          early_stopping: false
          # eos_token_id: 0
          num_return_sequences: 6
          top_k: 1000
          top_p: 0.3
      losses:
      - type: caption_cross_entropy
      # - type: in_batch_contrastive
      #   params:
      #     temperature: 1
      # - type: ln_attention_supervision
      #   params:
      #     super_type: mse
      image_feature_processor:
        type: spatial
        params:
          module: linear
          feat_dim: 2048
          pos_dim: 5
          hidden_size: 768
          hidden_dropout_prob: 0.1
      trace_feature_encoder:
        name: "tracebox_encoder"
        input_size: 5
        hidden_size: 768
        num_positions: 256
      metric:
        tokenizer:
          max_seq_length: 225
          sync_seg_reverse: false
          sync_seg_shuffle: false
          tokenizer_config:
            type: bert-base-uncased
            params:
              do_lower_case: True
      
      optimizer:
        type: adam_w
        params:
          lr: 5e-5
          eps: 1e-8

  
dataset_config:
  cvlg_coco2017:
    processors:
      caption_processor:
        params:
          max_seq_length: 225
          sync_seg_reverse: false
          sync_seg_shuffle: false
      trace_bbox_processor:
        params:
          sync_seg_reverse: false
          max_seq_length: 256

optimizer:
  type: adam_w
  params:
    lr: 5e-5
    eps: 1e-8

scheduler:
  type: warmup_linear
  params:
    num_warmup_steps: 1000
    num_training_steps: 11000

training:
  evaluation_interval: 5000
  checkpoint_interval: 5000
  clip_norm_mode: all
  clip_gradients: true
  max_grad_l2_norm: 0.25
  use_warmup: true
  warmup_factor: 0.2
  warmup_iterations: 1000
  batch_size: 32
  update_frequency: 8
  lr_scheduler: true
  detect_anomaly: true
  num_workers: 0
  # Don't forget to update schedule_attributes if you update this
  max_updates: 88000
  find_unused_parameters: true
  early_stop:
    criteria: val/cvlg_coco2017/traced_bert_caption_bleu4
    minimize: false

evaluation:
  metrics:
  - traced_bert_caption_bleu4
# checkpoint:
#   pretrained_state_mapping:
#     model.bert: model.bert
