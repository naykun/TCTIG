includes:
  - ./traced_caption_anno_lmdb_img_itp.yaml
  - ./defaults.yaml

model_config:
    cvlg:
      vae_type: vqgan
      deepspeed: true
      concate_trace: true
      base_model_name: t2i
      layers: 12
      encoder_layers: 3
      axial_decoder: true
      clip_encoder: true
      max_gen_length: 256
      vocab_size: 1024
      loop_contrastive: false
      tc_contrastive_aggregate_method: transformer
      inference:
        prompt: true
        type: nucleus_sampling
        args: 
          do_sample: true
          max_length: 257
          early_stopping: false
          # eos_token_id: 0
          num_return_sequences: 1
          top_k: 1000
          top_p: 0.3
      losses:
      - type: caption_cross_entropy
      # - type: in_batch_contrastive
      #   params:
      #     temperature: 1
      # - type: ln_attention_supervision
      #   params:
      #     super_type: mse
      image_feature_processor:
        type: spatial
        params:
          module: linear
          feat_dim: 2048
          pos_dim: 5
          hidden_size: 768
          hidden_dropout_prob: 0.1
      trace_feature_encoder:
        name: "tracebox_encoder"
        input_size: 5
        hidden_size: 768
        num_positions: 256
      metric:
        tokenizer:
          max_seq_length: 225
          sync_seg_reverse: false
          sync_seg_shuffle: false
          tokenizer_config:
            type: bert-base-uncased
            params:
              do_lower_case: True
      
      optimizer:
        type: adam_w
        params:
          lr: 5e-4
          beta: [0.9, 0.96]
          eps: 1.0e-8
          weight_decay: 4.5e-2
        warmup_step: 5000
        total_step: 8e5 

  
dataset_config:
  cvlg_coco2017:
    subset: openimage
    vae_type: vqgan
    dataset_class: dynamic
    tokenizer:
      max_trace_seq_length: 256
      max_caption_seq_length: 231
      delta: 0.1
      reverse: false
      time_window: 0.1
      caption_tokenizer_config:
        type: clip
        params:
          do_lower_case: True

optimizer:
  type: adam_w
  params:
    lr: 5e-5
    eps: 1e-8

scheduler:
  type: warmup_linear
  params:
    num_warmup_steps: 1000
    num_training_steps: 11000

training:
  evaluation_interval: 5000
  checkpoint_interval: 5000
  clip_norm_mode: all
  clip_gradients: true
  max_grad_l2_norm: 0.25
  use_warmup: true
  warmup_factor: 0.2
  warmup_iterations: 1000
  batch_size: 32
  update_frequency: 8
  lr_scheduler: true
  detect_anomaly: true
  num_workers: 0
  # Don't forget to update schedule_attributes if you update this
  max_updates: 88000
  find_unused_parameters: true
  early_stop:
    criteria: val/cvlg_coco2017/traced_bert_caption_bleu4
    minimize: false

evaluation:
  metrics:
  - traced_bert_caption_bleu4
# checkpoint:
#   pretrained_state_mapping:
#     model.bert: model.bert
